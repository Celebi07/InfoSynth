{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lbuq2IkBCC-G",
        "outputId": "23058668-4503-4061-abc3-6bd2f0fedeff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-telegram-bot\n",
            "  Downloading python_telegram_bot-20.6-py3-none-any.whl (548 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.5/548.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx~=0.25.0 (from python-telegram-bot)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.25.0->python-telegram-bot) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx~=0.25.0->python-telegram-bot) (2023.7.22)\n",
            "Collecting httpcore (from httpx~=0.25.0->python-telegram-bot)\n",
            "  Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx~=0.25.0->python-telegram-bot) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.25.0->python-telegram-bot) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx~=0.25.0->python-telegram-bot) (1.1.3)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore->httpx~=0.25.0->python-telegram-bot)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, python-telegram-bot\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.1 httpx-0.25.1 python-telegram-bot-20.6\n",
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2023.7.22)\n",
            "Installing collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-0.6.1\n",
            "Collecting openai\n",
            "  Downloading openai-1.1.1-py3-none-any.whl (217 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.8/217.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-1.1.1\n",
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.10/dist-packages (20.6)\n",
            "Requirement already satisfied: httpx~=0.25.0 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot) (0.25.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.25.0->python-telegram-bot) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx~=0.25.0->python-telegram-bot) (2023.7.22)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx~=0.25.0->python-telegram-bot) (1.0.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx~=0.25.0->python-telegram-bot) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.25.0->python-telegram-bot) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx~=0.25.0->python-telegram-bot) (1.1.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore->httpx~=0.25.0->python-telegram-bot) (0.14.0)\n",
            "Collecting python-telegram-bot==13.7\n",
            "  Downloading python_telegram_bot-13.7-py3-none-any.whl (490 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.1/490.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.7) (2023.7.22)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.7) (6.3.2)\n",
            "Collecting APScheduler==3.6.3 (from python-telegram-bot==13.7)\n",
            "  Downloading APScheduler-3.6.3-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.7) (2023.3.post1)\n",
            "Collecting cachetools==4.2.2 (from python-telegram-bot==13.7)\n",
            "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.7) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.7) (1.16.0)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.7) (5.2)\n",
            "Installing collected packages: cachetools, APScheduler, python-telegram-bot\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.3.2\n",
            "    Uninstalling cachetools-5.3.2:\n",
            "      Successfully uninstalled cachetools-5.3.2\n",
            "  Attempting uninstall: python-telegram-bot\n",
            "    Found existing installation: python-telegram-bot 20.6\n",
            "    Uninstalling python-telegram-bot-20.6:\n",
            "      Successfully uninstalled python-telegram-bot-20.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed APScheduler-3.6.3 cachetools-4.2.2 python-telegram-bot-13.7\n",
            "Collecting pyTelegramBotAPI\n",
            "  Downloading pyTelegramBotAPI-4.14.0.tar.gz (243 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.1/243.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pyTelegramBotAPI) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (2023.7.22)\n",
            "Building wheels for collected packages: pyTelegramBotAPI\n",
            "  Building wheel for pyTelegramBotAPI (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyTelegramBotAPI: filename=pyTelegramBotAPI-4.14.0-py3-none-any.whl size=215250 sha256=401bf8d8588b0d627cfcdcace68eaba6db4a99b8d3d6e79efcdfbf54c0d9b742\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/51/2d/24b40a366c85c37928d5aa36ddf257e5a79fad25e1ecd11b2c\n",
            "Successfully built pyTelegramBotAPI\n",
            "Installing collected packages: pyTelegramBotAPI\n",
            "Successfully installed pyTelegramBotAPI-4.14.0\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n",
            "Collecting textract\n",
            "  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
            "Collecting argcomplete~=1.10.0 (from textract)\n",
            "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting beautifulsoup4~=4.8.0 (from textract)\n",
            "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==3.* (from textract)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docx2txt~=0.8 (from textract)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting extract-msg<=0.29.* (from textract)\n",
            "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20191110 (from textract)\n",
            "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-pptx~=0.6.18 (from textract)\n",
            "  Downloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six~=1.12.0 (from textract)\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting SpeechRecognition~=3.8.1 (from textract)\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xlrd~=1.2.0 (from textract)\n",
            "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome (from pdfminer.six==20191110->textract)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.8.0->textract) (2.5)\n",
            "Collecting imapclient==2.1.0 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting olefile>=0.46 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tzlocal>=2.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (5.2)\n",
            "Collecting compressed-rtf>=1.0.6 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ebcdic>=1.1.1 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (4.9.3)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (9.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx~=0.6.18->textract)\n",
            "  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docx2txt, compressed-rtf, olefile\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=f5af93a8178ff55c28dfd344d1c8e9381cc83b8597103e7e1dfdee99ff55cfc0\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6184 sha256=2bce8d88f1b7d94eb5e4774c04b9e28a3416195fa4e4ba5027bdda0b4f0c07b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/3e/48/e7d833ecc516c36f8966d310b1a6386db091a718f1ff3bf85c\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=c4df7f306688657cf2ba52541663f09e0d9b7b328a82dfcf00aacd9136ee7683\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "Successfully built docx2txt compressed-rtf olefile\n",
            "Installing collected packages: SpeechRecognition, ebcdic, docx2txt, compressed-rtf, chardet, argcomplete, XlsxWriter, xlrd, six, pycryptodome, olefile, beautifulsoup4, python-pptx, pdfminer.six, imapclient, extract-msg, textract\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 2.0.1\n",
            "    Uninstalling xlrd-2.0.1:\n",
            "      Successfully uninstalled xlrd-2.0.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "pydrive2 1.6.3 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "yfinance 0.2.31 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SpeechRecognition-3.8.1 XlsxWriter-3.1.9 argcomplete-1.10.3 beautifulsoup4-4.8.2 chardet-3.0.4 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.19.0 python-pptx-0.6.23 six-1.12.0 textract-1.6.5 xlrd-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bs4\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.8.2)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.5)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=2de30f9331f7d57824e10f3f03365eb760f78bbe9b7ecdcd314d1515ae65e7df\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built bs4\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.1\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.12.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=cef0ca92ce2c8b5261bf8b80d6f746f5ed0a9f90459c39b8dfe734982982bc41\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install python-telegram-bot\n",
        "!pip install youtube_transcript_api\n",
        "!pip install openai\n",
        "!pip install --upgrade python-telegram-bot\n",
        "!pip install python-telegram-bot==13.7\n",
        "!pip install pyTelegramBotAPI\n",
        "!pip install transformers\n",
        "!pip install textract\n",
        "!pip install bs4\n",
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from youtube_transcript_api.formatters import TextFormatter\n",
        "import openai\n",
        "import os\n",
        "import textwrap\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import textwrap\n",
        "import textract\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "PROMPT_STRING = \"Summarize the following text:\\n<<SUMMARY>>\\n\"\n",
        "import os\n",
        "import telebot\n",
        "\n",
        "my_telegrambot_secret = \"6927138841:AAGus1-IIfKLUpiAyU1oBq0Ke_7eVp3GZ5k\"\n",
        "# API_KEY = os.getenv('API_KEY')\n",
        "bot = telebot.TeleBot(my_telegrambot_secret)\n",
        "\n",
        "# Create your AI model functions here\n",
        "def sentiment(message):\n",
        "    # Define the text to analyze\n",
        "    text = message\n",
        "\n",
        "    # Define the prompt and parameters for sentiment analysis\n",
        "    sentiment_prompt = (f\"Please analyze the sentiment of the following text:\\n{text}\\nSentiment:\")\n",
        "\n",
        "    # Define the GPT-3 parameters for sentiment analysis\n",
        "    sentiment_model = \"text-davinci-002\"\n",
        "    sentiment_temperature = 0.5\n",
        "    sentiment_max_tokens = 1\n",
        "\n",
        "    # Call the OpenAI GPT-3 API to analyze the sentiment\n",
        "    sentiment_response = openai.Completion.create(\n",
        "        engine=sentiment_model,\n",
        "        prompt=sentiment_prompt,\n",
        "        temperature=sentiment_temperature,\n",
        "        max_tokens=sentiment_max_tokens,\n",
        "    )\n",
        "\n",
        "    # Parse the response and return the sentiment\n",
        "    return sentiment_response.choices[0].text.strip()\n",
        "\n",
        "def summarize_video(video_link):\n",
        "    # Extract the video ID from the link\n",
        "    video_id = video_link.split(\"=\")[-1]\n",
        "\n",
        "    # Get transcript for given YouTube video id\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "\n",
        "    # Format transcript using TextFormatter from youtube_transcript_api library\n",
        "    formatter = TextFormatter()\n",
        "    transcript = formatter.format_transcript(transcript)\n",
        "\n",
        "    video_length = len(transcript)\n",
        "\n",
        "    # If the video is ~25 minutes or more, double the chunk size\n",
        "    # This is done to reduce overall amount of API calls\n",
        "    chunk_size = 4000 if video_length >= 25000 else 2000\n",
        "\n",
        "    # Wrap the transcript in chunks of characters\n",
        "    chunks = textwrap.wrap(transcript, chunk_size)\n",
        "\n",
        "    summaries = []\n",
        "\n",
        "    # For each chunk of characters, generate a summary\n",
        "    for chunk in chunks:\n",
        "        prompt = f\"Write a detailed summary of the following:\\n\\n{chunk}\\n\"\n",
        "\n",
        "        # Generate summary using GPT-3\n",
        "        # If the davinci model is incurring too much cost,\n",
        "        # the text-curie-001 model may be used in its place.\n",
        "        response = openai.Completion.create(\n",
        "            model=\"text-davinci-003\", prompt=prompt, max_tokens=256\n",
        "        )\n",
        "        summary = re.sub(\"\\s+\", \" \", response.choices[0].text.strip())\n",
        "        summaries.append(summary)\n",
        "\n",
        "    # Join the chunk summaries into one string\n",
        "    chunk_summaries = \" \".join(summaries)\n",
        "    prompt = f\"Write a detailed summary of the following:\\n\\n{chunk_summaries}\\n\"\n",
        "\n",
        "    # Generate a final summary from the chunk summaries\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\", prompt=prompt, max_tokens=2056\n",
        "    )\n",
        "    final_summary = re.sub(\"\\s+\", \" \", response.choices[0].text.strip())\n",
        "\n",
        "    # Return all of the summaries as a dictionary\n",
        "\n",
        "    return final_summary\n",
        "\n",
        "\n",
        "def summarize_website(url):\n",
        "    # Get the text content from the website\n",
        "    print(\"website0\")\n",
        "    website_text = get_website_text(url)\n",
        "    print(\"website1\")\n",
        "\n",
        "\n",
        "    # Split the text content into chunks of characters\n",
        "    chunk_size = 2000\n",
        "    chunks = textwrap.wrap(website_text, chunk_size)\n",
        "    print(chunks)\n",
        "    summaries = list()\n",
        "\n",
        "    # For each chunk of characters, generate a summary\n",
        "    for chunk in chunks:\n",
        "        print(\"website2\")\n",
        "        prompt = PROMPT_STRING.replace(\"<<SUMMARY>>\", chunk)\n",
        "\n",
        "        print(f\"prompt0: {prompt}\")\n",
        "        # Generate summary using GPT-3\n",
        "        response = openai.Completion.create(\n",
        "            model=\"text-davinci-002\", prompt=prompt, max_tokens=256\n",
        "        )\n",
        "        print(\"website3\")\n",
        "\n",
        "        summary = re.sub(\"\\s+\", \" \", response.choices[0].text.strip())\n",
        "        summaries.append(summary)\n",
        "\n",
        "    # Join the chunk summaries into one string\n",
        "    chunk_summaries = \" \".join(summaries)\n",
        "    prompt = PROMPT_STRING.replace(\"<<SUMMARY>>\", chunk_summaries)\n",
        "    print(f\"prompt: {prompt}\")\n",
        "\n",
        "    # Generate a final summary from the chunk summaries\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-002\", prompt=prompt, max_tokens=2056\n",
        "    )\n",
        "    final_summary = re.sub(\"\\s+\", \" \", response.choices[0].text.strip())\n",
        "    print(\"website5\")\n",
        "\n",
        "    return final_summary\n",
        "\n",
        "from langdetect import detect\n",
        "def generate_convert(message):\n",
        "    # Detect the language of the input text\n",
        "    language = detect(message)\n",
        "    # Call the GPT-3 API to generate summary\n",
        "    prompt = f\"Please generate a summary in {language} for the following text:\\n{message}\"\n",
        "    response = openai.Completion.create(\n",
        "        engine='text-davinci-002',\n",
        "        prompt=prompt,\n",
        "        max_tokens=1024,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.3,\n",
        "    )\n",
        "    # Get the generated summary from the API response\n",
        "    summary = response.choices[0].text.strip()\n",
        "    return summary\n",
        "def summarize_pdf(file_name):\n",
        "    # Extract text from PDF\n",
        "    text = textract.process(file_name).decode('utf-8')\n",
        "\n",
        "    # Summarize the extracted text using GPT-3\n",
        "    summary = openai.Completion.create(\n",
        "        model=\"text-davinci-002\",\n",
        "        prompt=f\"Please summarize the following text:\\n{text}\",\n",
        "        temperature=0,\n",
        "        # max_tokens=200\n",
        "    )\n",
        "\n",
        "    return summary.choices[0].text.strip()\n",
        "def summarize_text(text):\n",
        "    # Split the text into chunks of characters\n",
        "    chunk_size = 2000\n",
        "    chunks = textwrap.wrap(text, chunk_size)\n",
        "\n",
        "    summaries = list()\n",
        "\n",
        "    # For each chunk of characters, generate a summary\n",
        "    for chunk in chunks:\n",
        "        prompt = PROMPT_STRING.replace(\"<<SUMMARY>>\", chunk)\n",
        "\n",
        "        # Generate summary using GPT-3\n",
        "        response = openai.Completion.create(\n",
        "            model=\"text-davinci-002\", prompt=prompt, max_tokens=256\n",
        "        )\n",
        "        summary = re.sub(\"\\s+\", \" \", response.choices[0].text.strip())\n",
        "        summaries.append(summary)\n",
        "\n",
        "    # Join the chunk summaries into one string\n",
        "    chunk_summaries = \" \".join(summaries)\n",
        "    prompt = PROMPT_STRING.replace(\"<<SUMMARY>>\", chunk_summaries)\n",
        "\n",
        "    # Generate a final summary from the chunk summaries\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-002\", prompt=prompt, max_tokens=2056\n",
        "    )\n",
        "    final_summary = re.sub(\"\\s+\", \" \", response.choices[0].text.strip())\n",
        "\n",
        "    return final_summary\n",
        "\n",
        "def get_website_text(url):\n",
        "    # Make a GET request to the website URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Parse the HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Extract the text content from the HTML using the 'get_text' method\n",
        "    website_text = soup.get_text()\n",
        "\n",
        "    # Remove any extra whitespace and newlines\n",
        "    website_text = re.sub(r'\\s+', ' ', website_text).strip()\n",
        "    print(website_text)\n",
        "    return website_text\n",
        "\n",
        "# Create a function to determine the type of the link\n",
        "\n",
        "# Create a function to handle incoming messages\n",
        "\n",
        "@bot.message_handler(commands=['Greet'])\n",
        "def greet(message):\n",
        "    bot.reply_to(message, \"Hey! How's it going?\")\n",
        "\n",
        "@bot.message_handler(commands=['hello'])\n",
        "def hello(message):\n",
        "    bot.send_message(message.chat.id, \"Hello!\")\n",
        "\n",
        "@bot.message_handler(commands=['start'])\n",
        "def ask_content_type(message):\n",
        "    bot.send_message(chat_id=message.chat.id, text=\"What type of content do you want to do? Please choose one of the following options:\\n\\n1. Summarize YouTube video\\n2. Summarize Website link\\n3. Summarize Document\\n4. Summarize text\\n5. Convert to English\")\n",
        "\n",
        "    bot.register_next_step_handler(message, process_content_type)\n",
        "\n",
        "def process_content_type(message):\n",
        "    content_type = message.text.lower()\n",
        "\n",
        "    if content_type == '1':\n",
        "        bot.send_message(chat_id=message.chat.id, text=\"Please enter the YouTube video URL you want to summarize\")\n",
        "        bot.register_next_step_handler(message, summarize_youtube_video)\n",
        "    elif content_type == '2':\n",
        "        bot.send_message(chat_id=message.chat.id, text=\"Please enter the website URL you want to summarize\")\n",
        "        bot.register_next_step_handler(message, summarize_website_link)\n",
        "    elif content_type == '3':\n",
        "        bot.send_message(chat_id=message.chat.id, text=\"Please upload the document you want to summarize\")\n",
        "        bot.register_next_step_handler(message, summarize_document)\n",
        "    elif content_type == '5':\n",
        "        bot.send_message(chat_id=message.chat.id, text=\"Please upload the text you want to convert\")\n",
        "        bot.register_next_step_handler(message, converter)\n",
        "    elif content_type == '4':\n",
        "        bot.send_message(chat_id=message.chat.id, text=\"Please upload the text you want to summarize\")\n",
        "        bot.register_next_step_handler(message, converter)\n",
        "    else:\n",
        "        bot.send_message(chat_id=message.chat.id, text=\"Sorry, I didn't understand that. Please choose one of the following options:\\n\\n1. YouTube video\\n2. Website link\\n3. Document\\n4. Convert to English\")\n",
        "        bot.register_next_step_handler(message, process_content_type)\n",
        "def summarizer_text(message):\n",
        "    print(\"d\")\n",
        "    text=message.text\n",
        "    summary=summarize_text(text)\n",
        "    sent=sentiment(summary)\n",
        "    bot.send_message(chat_id=message.chat.id, text=summary)\n",
        "    bot.send_message(chat_id=message.chat.id, text=sent)\n",
        "def converter(message):\n",
        "    print(\"c\")\n",
        "    conv=message.text\n",
        "    summary= generate_convert(conv)\n",
        "    sent=sentiment(summary)\n",
        "    bot.send_message(chat_id=message.chat.id, text=summary)\n",
        "    bot.send_message(chat_id=message.chat.id, text=sent)\n",
        "def summarize_youtube_video(message):\n",
        "    print(\"yt\")\n",
        "    video_url = message.text\n",
        "    summary = summarize_video(video_url)\n",
        "    sent=sentiment(summary)\n",
        "    bot.send_message(chat_id=message.chat.id, text=summary)\n",
        "    bot.send_message(chat_id=message.chat.id, text=sent)\n",
        "def summarize_website_link(message):\n",
        "    print(\"website\")\n",
        "    website_url = message.text\n",
        "    summary = summarize_website(website_url)\n",
        "    sent=sentiment(summary)\n",
        "    bot.send_message(chat_id=message.chat.id, text=summary)\n",
        "    bot.send_message(chat_id=message.chat.id, text=sent)\n",
        "@bot.message_handler(content_types=['document'])\n",
        "def summarize_document(message):\n",
        "    # handle uploaded document\n",
        "        file_id = message.document.file_id\n",
        "        file_name = message.document.file_name\n",
        "\n",
        "        bot = telebot.TeleBot(\"5632868573:AAHVK_LEzgFKNgy9SHUPC2M_9yX-B1l8YDs\")\n",
        "        file_info = bot.get_file(file_id)\n",
        "        file_path = file_info.file_path\n",
        "\n",
        "        # Download the file to the server\n",
        "        downloaded_file = bot.download_file(file_path)\n",
        "        with open(file_name, 'wb') as f:\n",
        "            f.write(downloaded_file)\n",
        "\n",
        "        pdf_path = file_name\n",
        "\n",
        "        textt = summarize_pdf(pdf_path)\n",
        "        bot.send_message(chat_id=message.chat.id, text=textt)\n",
        "        sent=sentiment(textt)\n",
        "        bot.send_message(chat_id=message.chat.id, text=sent)\n",
        "bot.polling()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "SthSgZ1PCI5g",
        "outputId": "2653d811-21f0-44af-e892-54d38e63f379"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-11a688b7cb04>\u001b[0m in \u001b[0;36m<cell line: 300>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0msent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/telebot/__init__.py\u001b[0m in \u001b[0;36mpolling\u001b[0;34m(self, non_stop, skip_pending, interval, timeout, long_polling_timeout, logger_level, allowed_updates, none_stop, restart_on_change, path_to_watch)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             self.__threaded_polling(non_stop=non_stop, interval=interval, timeout=timeout, long_polling_timeout=long_polling_timeout,\n\u001b[0m\u001b[1;32m   1044\u001b[0m                                     logger_level=logger_level, allowed_updates=allowed_updates)\n\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/telebot/__init__.py\u001b[0m in \u001b[0;36m__threaded_polling\u001b[0;34m(self, non_stop, interval, timeout, long_polling_timeout, logger_level, allowed_updates)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                     \u001b[0mpolling_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                     \u001b[0mpolling_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/telebot/__init__.py\u001b[0m in \u001b[0;36m__threaded_polling\u001b[0;34m(self, non_stop, interval, timeout, long_polling_timeout, logger_level, allowed_updates)\u001b[0m\n\u001b[1;32m   1072\u001b[0m                 \u001b[0mor_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait for polling thread finish, polling thread error or thread pool error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m                 \u001b[0mpolling_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m                 \u001b[0merror_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mapihelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApiException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/telebot/util.py\u001b[0m in \u001b[0;36mraise_exceptions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraise_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/telebot/util.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceived_task_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Task complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-11a688b7cb04>\u001b[0m in \u001b[0;36msummarize_youtube_video\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0mvideo_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0msent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-11a688b7cb04>\u001b[0m in \u001b[0;36msummarize_video\u001b[0;34m(video_link)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# If the davinci model is incurring too much cost,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# the text-curie-001 model may be used in its place.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         response = openai.Completion.create(\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-003\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'Completion'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypmfMQfmERAa",
        "outputId": "e857438e-f0d3-42b5-ae21-1da3726d8436"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ]
    }
  ]
}